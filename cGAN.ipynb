{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cGAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush12gupta/GAN-Implementations/blob/master/cGAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqhF8lmMs13h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYSM2Ehms9Pg",
        "colab_type": "code",
        "outputId": "4e368339-bccd-4b35-cb23-58346869b98f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 798
        }
      },
      "source": [
        "VERSION = \"20200325\"  #@param [\"1.5\" , \"20200325\", \"nightly\"]\n",
        "!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n",
        "!python pytorch-xla-env-setup.py --version $VERSION"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  3727  100  3727    0     0  36900      0 --:--:-- --:--:-- --:--:-- 36900\n",
            "Updating TPU and VM. This may take around 2 minutes.\n",
            "Updating TPU runtime to pytorch-dev20200325 ...\n",
            "Uninstalling torch-1.5.0a0+d6149a7:\n",
            "  Successfully uninstalled torch-1.5.0a0+d6149a7\n",
            "Uninstalling torchvision-0.6.0a0+3c254fb:\n",
            "  Successfully uninstalled torchvision-0.6.0a0+3c254fb\n",
            "Copying gs://tpu-pytorch/wheels/torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][ 83.4 MiB/ 83.4 MiB]                                                \n",
            "Operation completed over 1 objects/83.4 MiB.                                     \n",
            "Copying gs://tpu-pytorch/wheels/torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "- [1 files][114.5 MiB/114.5 MiB]                                                \n",
            "Operation completed over 1 objects/114.5 MiB.                                    \n",
            "Copying gs://tpu-pytorch/wheels/torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl...\n",
            "/ [1 files][  2.5 MiB/  2.5 MiB]                                                \n",
            "Operation completed over 1 objects/2.5 MiB.                                      \n",
            "Processing ./torch-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==nightly+20200325) (0.16.0)\n",
            "Done updating TPU runtime: <Response [200]>\n",
            "\u001b[31mERROR: fastai 1.0.61 requires torchvision, which is not installed.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.5.0a0+d6149a7\n",
            "Processing ./torch_xla-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: torch-xla\n",
            "  Found existing installation: torch-xla 1.6+e788e5b\n",
            "    Uninstalling torch-xla-1.6+e788e5b:\n",
            "      Successfully uninstalled torch-xla-1.6+e788e5b\n",
            "Successfully installed torch-xla-1.6+e788e5b\n",
            "Processing ./torchvision-nightly+20200325-cp36-cp36m-linux_x86_64.whl\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.5.0a0+d6149a7)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (7.0.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision==nightly+20200325) (1.18.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchvision==nightly+20200325) (0.16.0)\n",
            "Installing collected packages: torchvision\n",
            "Successfully installed torchvision-0.6.0a0+3c254fb\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libomp5 is already the newest version (5.0.1-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 29 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBe3EBhhWJNU",
        "colab_type": "code",
        "outputId": "292cbe01-a7bf-4cd2-cde8-a31e112ef720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "\n",
        "# \"Map function\": acquires a corresponding Cloud TPU core, creates a tensor on it,\n",
        "# and prints its core\n",
        "def simple_map_fn(index, flags):\n",
        "  # Sets a common random seed - both for initialization and ensuring graph is the same\n",
        "  torch.manual_seed(1234)\n",
        "\n",
        "  # Acquires the (unique) Cloud TPU core corresponding to this process's index\n",
        "  device = xm.xla_device()  \n",
        "\n",
        "  # Creates a tensor on this process's device\n",
        "  t = torch.randn((2, 2), device=device)\n",
        "\n",
        "  print(\"Process\", index ,\"is using\", xm.xla_real_devices([str(device)])[0])\n",
        "\n",
        "  # Barrier to prevent master from exiting before workers connect.\n",
        "  xm.rendezvous('init')\n",
        "\n",
        "# Spawns eight of the map functions, one for each of the eight cores on\n",
        "# the Cloud TPU\n",
        "flags = {}\n",
        "# Note: Colab only supports start_method='fork'\n",
        "xmp.spawn(simple_map_fn, args=(flags,), nprocs=8, start_method='fork')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Process 0 is using TPU:0\n",
            "Process 6 is using TPU:6\n",
            "Process 2 is using TPU:2\n",
            "Process 3 is using TPU:3\n",
            "Process 5 is using TPU:5\n",
            "Process 7 is using TPU:7\n",
            "Process 4 is using TPU:4\n",
            "Process 1 is using TPU:1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7pBGa5SR_Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "import torch_xla.distributed.parallel_loader as pl\n",
        "import torch\n",
        "import torch.optim as opt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from torchvision import datasets\n",
        "import torchsummary\n",
        "from torchsummary import summary\n",
        "from torch.autograd import Variable\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MS4IpuzRZneR",
        "colab_type": "code",
        "outputId": "ae3b92df-43f0-47b4-c0f2-081f6a4e6167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "######## Dataset ###########\n",
        "transform=transforms.Compose([transforms.Resize(32), \n",
        "         transforms.CenterCrop(32),\n",
        "         transforms.ToTensor(), \n",
        "         transforms.Normalize((0.5,), (0.5,))])\n",
        "if not xm.is_master_ordinal():\n",
        "    xm.rendezvous('download_only_once')\n",
        "dataset = datasets.CIFAR10(root='./content', train=True,download=True, transform=transform)\n",
        "\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size = 32, shuffle=True)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16hKeoPORdtx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Epoch = 100\n",
        "channel = 3\n",
        "image_size = 32\n",
        "latent_dim = 100\n",
        "num_class = 10\n",
        "batch_size = 32\n",
        "##'cuda:0'\n",
        "image_shape = (channel, image_size, image_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVns0U8_HiKu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "\n",
        "    self.label_embedding = nn.Embedding(10,10)\n",
        "    self.layer = 128\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(latent_dim+num_class, self.layer),\n",
        "        nn.BatchNorm1d(self.layer,0.8),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(self.layer, self.layer*2),\n",
        "        nn.BatchNorm1d(self.layer*2,0.8),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(self.layer*2, self.layer*4),\n",
        "        nn.BatchNorm1d(self.layer*4,0.8),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(self.layer*4, self.layer*8),\n",
        "        nn.BatchNorm1d(self.layer*8,0.8),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Linear(self.layer*8,channel*image_size*image_size),\n",
        "        nn.Tanh()        \n",
        "    )  \n",
        "\n",
        "\n",
        "  def forward(self, noise, labels):\n",
        "    c = self.label_embedding(labels)\n",
        "    #print(noise.shape)\n",
        "    z = noise.view(noise.size(0),latent_dim)\n",
        "    x = torch.cat([c,z],1)\n",
        "    out = self.model(x)\n",
        "    return out.view(out.size(0),channel,image_size,image_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPZQ0yHZkFMK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator,self).__init__()\n",
        "    self.label_embedding = nn.Embedding(10,10)\n",
        "    self.layer = 256\n",
        "    \n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(num_class+(channel*image_size*image_size),self.layer*4),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(self.layer*4,self.layer*2),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(self.layer*2,self.layer),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(self.layer, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "\n",
        "  def forward(self, img, label):\n",
        "    x = img.view(img.size(0),-1)\n",
        "    #print(x.shape)\n",
        "    z = self.label_embedding(label)\n",
        "    x = torch.cat([x, z],1)\n",
        "    out = self.model(x)\n",
        "    return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blajrzIHPUt-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  def init_weights(m): \n",
        "    if type(m)==nn.Linear:\n",
        "        torch.nn.init.xavier_uniform(m.weight)\n",
        "        m.bias.data.fill_(0.01)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52WUSnROFlq8",
        "colab_type": "code",
        "outputId": "28bcdfb1-5d88-4a9e-c2e3-9cf680f80446",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "generator = Generator().to(device)\n",
        "gen_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "discriminator = Discriminator().to(device)\n",
        "discriminator.apply(init_weights)\n",
        "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Loss functions \n",
        "a_loss = torch.nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfsPE6aIPoIM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "real_label = 0.9\n",
        "fake_label = 0.0\n",
        "\n",
        "label_type = torch.LongTensor#.to(device)\n",
        "img_type = torch.FloatTensor#.to(device)\n",
        "\n",
        "if device=='cuda:0': \n",
        "    generator.to(device)\n",
        "    discriminator.to(device)\n",
        "    a_loss.to(device)\n",
        "    label_type = torch.cuda.LongTensor\n",
        "    img_type = torch.cuda.FloatTensor\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEP-8i7pvIbG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fix_noise = torch.FloatTensor(np.random.normal(0, 1,(batch_size, latent_dim))).to(device) # To evaluate on a particular noise\n",
        "fix_label = torch.LongTensor(np.random.randint(0, num_class, batch_size)).to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPym7kNwAeJe",
        "colab_type": "code",
        "outputId": "56a048de-be92-42b5-e374-d4a888334cb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "G_Loss_FM = G_losses\n",
        "D_Loss_FM = D_losses"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9db36c3c44d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mG_Loss_FM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mD_Loss_FM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mD_losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'G_losses' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gHMkw6NsXes",
        "colab_type": "code",
        "outputId": "40fb6f7b-2123-4bbb-8bf9-17bae6afb3e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "G_losses = []\n",
        "D_losses = []\n",
        "for epoch in range(1,Epoch+1):\n",
        "  G_loss=0.\n",
        "  D_loss=0.\n",
        "  for i, data in enumerate(dataloader):\n",
        "    (imgs,labels) = data\n",
        "    batch_size = imgs.shape[0]\n",
        "    imgs = Variable(imgs.type(img_type)).to(device)\n",
        "    labels = Variable(labels.type(label_type)).to(device)\n",
        "\n",
        "    # Creating real and fake label for calculation of loss\n",
        "    r_label = Variable(img_type(batch_size,1).fill_(real_label)).to(device)\n",
        "    f_label = Variable(img_type(batch_size,1).fill_(fake_label)).to(device)\n",
        "\n",
        "    # Training Generator\n",
        "\n",
        "    gen_optimizer.zero_grad()\n",
        "\n",
        "    noise = Variable(img_type(np.random.normal(0, 1,(batch_size, latent_dim)))).to(device)\n",
        "    rand_label = Variable(label_type(np.random.randint(0, num_class, batch_size))).to(device)\n",
        "    dis = discriminator(generator(noise, rand_label),rand_label)\n",
        "    #print(type(dis),'  ',type(r_label))\n",
        "    g_loss = a_loss(dis,r_label)\n",
        "    g_loss.backward()\n",
        "    gen_optimizer.step()\n",
        "\n",
        "    # Training Discriminator\n",
        "\n",
        "    d_optimizer.zero_grad()\n",
        "\n",
        "    noise = Variable(img_type(np.random.normal(0, 1,(batch_size, latent_dim)))).to(device)\n",
        "    rand_label = Variable(label_type(np.random.randint(0, num_class, batch_size))).to(device)\n",
        "\n",
        "    d_real = discriminator(imgs, labels)\n",
        "    loss_real = a_loss(d_real, r_label)\n",
        "\n",
        "    d_fake = discriminator(generator(noise,rand_label).detach(),rand_label)\n",
        "    loss_fake = a_loss(d_fake, f_label)\n",
        "\n",
        "    d_loss = 0.5*(loss_fake+loss_real)\n",
        "\n",
        "    d_loss.backward()\n",
        "    d_optimizer.step()\n",
        "\n",
        "    G_loss += g_loss.item()\n",
        "    D_loss += d_loss.item()\n",
        "\n",
        "    if i%100 == 0: \n",
        "        \n",
        "        static_fake = generator(fix_noise, fix_label)\n",
        "        vutils.save_image(static_fake.detach(), '/content/drive/My Drive/cGAN/Image/samples_%d.png' % (epoch), normalize=True)\n",
        "\n",
        "  print('Epoch {} || G_loss: {} || D_loss: {}'.format(epoch,G_loss/(i+1),D_loss/(i+1)))\n",
        "  #print('Epoch {} || G_loss: {} || D_loss: {}'.format(epoch,g_loss.item(),d_loss.item()))\n",
        "  G_losses.append(G_loss/(i+1))\n",
        "  D_losses.append(D_loss/(i+1))\n",
        "  # static_fake = generator(fix_noise, fix_label)\n",
        "  # plt.imshow(static_fake.squeeze().detach().cpu(),normalize=True)#.view(channel,image_size,image_size\n",
        "  # plt.show()\n",
        "  # plt.savefig('/content/drive/My Drive/cGAN/Image/fake_samples_epoch_%03d.png' % (epoch))\n",
        "  # #Checkpoint\n",
        "  torch.save(generator.state_dict(),'/content/drive/My Drive/cGAN/generator/generator_{}_.pth'.format(epoch))\n",
        "  torch.save(discriminator.state_dict(),'/content/drive/My Drive/cGAN/discriminator/discriminator_{}_.pth'.format(epoch))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-bd8487bd86d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mG_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mg_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0mD_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFaE_8DH1E21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C94t8Rp4kxYn",
        "colab_type": "code",
        "outputId": "c95befc4-be37-4bb4-c735-76cbfd4446eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJbswCJbKlX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def map_fn(index):\n",
        "\n",
        "  torch.manual_seed(1234)\n",
        "\n",
        "  device = xm.xla_device() \n",
        "\n",
        "  \n",
        "  transform=transforms.Compose([transforms.Resize(32), \n",
        "         transforms.CenterCrop(32),\n",
        "         transforms.ToTensor(), \n",
        "         transforms.Normalize((0.5,), (0.5,))])\n",
        "  \n",
        "  if not xm.is_master_ordinal():\n",
        "    xm.rendezvous('download_only_once')\n",
        "\n",
        "  train_dataset = datasets.CIFAR10(\n",
        "    \"./content\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform)\n",
        "\n",
        "  if xm.is_master_ordinal():\n",
        "    xm.rendezvous('download_only_once')\n",
        "  \n",
        "  # Creates the (distributed) train sampler, which let this process only access\n",
        "  # its portion of the training dataset.\n",
        "  train_sampler = torch.utils.data.distributed.DistributedSampler(\n",
        "    train_dataset,\n",
        "    num_replicas=xm.xrt_world_size(),\n",
        "    rank=xm.get_ordinal(),\n",
        "    shuffle=True)\n",
        "\n",
        "  \n",
        "  # Creates dataloaders, which load data in batches\n",
        "  # Note: test loader is not shuffled or sampled\n",
        "  dataloader = torch.utils.data.DataLoader(\n",
        "      train_dataset,\n",
        "      batch_size=32,\n",
        "      sampler=train_sampler,\n",
        "      num_workers=8,\n",
        "      drop_last=True)\n",
        "  \n",
        "  generator = Generator().to(device)\n",
        "  gen_optimizer = torch.optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "  discriminator = Discriminator().to(device)\n",
        "  discriminator.apply(init_weights)\n",
        "  d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "  a_loss = torch.nn.BCELoss()\n",
        "\n",
        "  for epoch in range(1,Epoch+1):\n",
        "    para_train_loader = pl.ParallelLoader(dataloader, [device]).per_device_loader(device)\n",
        "    G_loss=0.\n",
        "    D_loss=0.\n",
        "    for i, data in enumerate(para_train_loader):\n",
        "      (imgs,labels) = data\n",
        "      batch_size = imgs.shape[0]\n",
        "      imgs = Variable(imgs.type(img_type)).to(device)\n",
        "      labels = Variable(labels.type(label_type)).to(device)\n",
        "\n",
        "      # Creating real and fake label for calculation of loss\n",
        "      r_label = Variable(img_type(batch_size,1).fill_(real_label)).to(device)\n",
        "      f_label = Variable(img_type(batch_size,1).fill_(fake_label)).to(device)\n",
        "\n",
        "      # Training Generator\n",
        "\n",
        "      gen_optimizer.zero_grad()\n",
        "\n",
        "      noise = Variable(img_type(np.random.normal(0, 1,(batch_size, latent_dim)))).to(device)\n",
        "      rand_label = Variable(label_type(np.random.randint(0, num_class, batch_size))).to(device)\n",
        "      dis = discriminator(generator(noise, rand_label),rand_label)\n",
        "      #print(type(dis),'  ',type(r_label))\n",
        "      g_loss = a_loss(dis,r_label)\n",
        "      g_loss.backward()\n",
        "      #gen_optimizer.step()\n",
        "      xm.optimizer_step(gen_optimizer)\n",
        "\n",
        "      # Training Discriminator\n",
        "\n",
        "      d_optimizer.zero_grad()\n",
        "\n",
        "      noise = Variable(img_type(np.random.normal(0, 1,(batch_size, latent_dim)))).to(device)\n",
        "      rand_label = Variable(label_type(np.random.randint(0, num_class, batch_size))).to(device)\n",
        "\n",
        "      d_real = discriminator(imgs, labels)\n",
        "      loss_real = a_loss(d_real, r_label)\n",
        "\n",
        "      d_fake = discriminator(generator(noise,rand_label).detach(),rand_label)\n",
        "      loss_fake = a_loss(d_fake, f_label)\n",
        "\n",
        "      d_loss = 0.5*(loss_fake+loss_real)\n",
        "\n",
        "      d_loss.backward()\n",
        "      #d_optimizer.step()\n",
        "      xm.optimizer_step(d_optimizer)\n",
        "\n",
        "      G_loss += g_loss.item()\n",
        "      D_loss += d_loss.item()\n",
        "\n",
        "      if i%100 == 0: \n",
        "        \n",
        "        static_fake = generator(fix_noise, fix_label)\n",
        "        vutils.save_image(static_fake.detach(), '/content/drive/My Drive/cGAN/Image/samples_%d.png' % (epoch), normalize=True)\n",
        "\n",
        "    print('Epoch {} || G_loss: {} || D_loss: {}'.format(epoch,G_loss/(i+1),D_loss/(i+1)))\n",
        "    #print('Epoch {} || G_loss: {} || D_loss: {}'.format(epoch,g_loss.item(),d_loss.item()))\n",
        "    G_losses.append(G_loss/(i+1))\n",
        "    D_losses.append(D_loss/(i+1))\n",
        "    # static_fake = generator(fix_noise, fix_label)\n",
        "    # plt.imshow(static_fake.squeeze().detach().cpu(),normalize=True)#.view(channel,image_size,image_size\n",
        "    # plt.show()\n",
        "    # plt.savefig('/content/drive/My Drive/cGAN/Image/fake_samples_epoch_%03d.png' % (epoch))\n",
        "    # #Checkpoint\n",
        "    torch.save(generator.state_dict(),'/content/drive/My Drive/cGAN/generator/generator_{}_.pth'.format(epoch))\n",
        "    torch.save(discriminator.state_dict(),'/content/drive/My Drive/cGAN/discriminator/discriminator_{}_.pth'.format(epoch))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elra_JUFR-me",
        "colab_type": "code",
        "outputId": "2677caf0-2737-4bab-b12e-ff8d61b066d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        }
      },
      "source": [
        "xmp.spawn(map_fn, args=(), nprocs=8, start_method='fork')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-a64ac2568ee2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspawn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnprocs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fork'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\u001b[0m in \u001b[0;36mspawn\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mjoin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0mdaemon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdaemon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         start_method=start_method)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mstart_processes\u001b[0;34m(fn, args, nprocs, join, daemon, start_method)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;31m# Loop on join until it returns True or raises an exception.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n\\n-- Process %d terminated with the following error:\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0merror_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0moriginal_trace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: \n\n-- Process 0 terminated with the following error:\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.6/dist-packages/torch/multiprocessing/spawn.py\", line 20, in _wrap\n    fn(i, *args)\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 116, in _start_fn\n    _setup_replication()\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/distributed/xla_multiprocessing.py\", line 109, in _setup_replication\n    xm.set_replication(str(device), [str(device)])\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 194, in set_replication\n    replication_devices = xla_replication_devices(devices)\n  File \"/usr/local/lib/python3.6/dist-packages/torch_xla/core/xla_model.py\", line 181, in xla_replication_devices\n    .format(len(local_devices), len(kind_devices)))\nRuntimeError: Cannot replicate if number of devices (1) is different from 8\n"
          ]
        }
      ]
    }
  ]
}