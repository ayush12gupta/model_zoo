{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO0gXBd9arDAVXo947Q3PDh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush12gupta/CNN_models/blob/master/ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wdoSeW-NXXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muKii7CzN3Sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(self, inp, out, strides=1):\n",
        "      super().__init__()\n",
        "\n",
        "      self.cov1 = nn.Conv2d(inp, out, 3, padding=1, bias=False, stride=strides)\n",
        "      self.bn1 = nn.BatchNorm2d(out)\n",
        "      self.cov2 = nn.Conv2d(out, out, 3, padding=1, bias=False) # For same size of layer as the previour one\n",
        "      self.bn2 = nn.BatchNorm2d(out)\n",
        "\n",
        "      self.shortcut = nn.Sequential()\n",
        "      if strides!=1 or inp!=out:\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(inp, out,1,stride = strides,bias=False),\n",
        "            nn.BatchNorm2d(out)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        iden = x\n",
        "        x = F.relu(self.bn1(self.cov1(x)))\n",
        "        x = self.bn2(self.cov2(x))\n",
        "        x += self.shortcut(iden)\n",
        "        \n",
        "        return F.relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZGKSHE0184G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, size, n,classnum=10):\n",
        "\n",
        "        super().__init__()\n",
        "        self.cov1 = nn.Conv2d(3, size[0], 3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(size[0])\n",
        "        self.cb1 = self.covBlock(block, size[0],n,stride=1)\n",
        "        self.cb2 = self.covBlock(block, (size[0],size[1]),n,stride=2)\n",
        "        self.cb3 = self.covBlock(block, (size[1],size[2]),n,stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(2)\n",
        "        self.fc = nn.Linear(2*2*size[2],classnum)\n",
        "\n",
        "    def covBlock(self,block,size,n,stride):\n",
        "\n",
        "        if stride!=1:\n",
        "          inp,out = size\n",
        "        else:\n",
        "          inp,out = size,size\n",
        "\n",
        "        layer = []\n",
        "        layer.append(block(inp,out,stride))\n",
        "        for i in range(n-1):\n",
        "          layer.append(block(out,out))\n",
        "\n",
        "        cb = nn.Sequential(*layer)\n",
        "        return cb  \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.bn1(self.cov1(x))) \n",
        "        x = self.cb1(x)\n",
        "        x = self.cb2(x)\n",
        "        x = self.cb3(x)  \n",
        "        x = self.avgpool(x)\n",
        "        res = 1\n",
        "        for dim in x[0].shape:\n",
        "            res *= dim  ##############\n",
        "        x = x.view(-1, res)\n",
        "        x = self.fc(x)\n",
        "        x = F.softmax(x,dim=1)\n",
        "\n",
        "        return x            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjCMCapX8GDO",
        "colab_type": "code",
        "outputId": "70966dc2-4e02-4da5-eff3-dd15092b7228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "batch_size = 128\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root = './data', download = True, train = True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', download = True, train = False, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = True, num_workers=2) # num workers is used to pre process data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHmVMBVrXlI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet(block, [16,32,64], 5).cuda()\n",
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,50,80], gamma=0.3)\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFatoDydX0gs",
        "colab_type": "code",
        "outputId": "3c691bbf-eb18-4ca0-c901-4812fd7a0437",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "model.train()\n",
        "print('Training Started')\n",
        "for epoch in range(100):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    correct, total = 0, 0\n",
        "    correct_epoch, total_epoch = 0, 0\n",
        "    scheduler.step()\n",
        "    for i,data in enumerate(trainloader):\n",
        "\n",
        "        inp,lab = data[0].to(device),data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(inp)\n",
        "        loss = criterion(out,lab)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        c = (torch.argmax(out,1)==lab)\n",
        "        correct+=torch.sum(c)\n",
        "        total += 128\n",
        "        correct_epoch += torch.sum(c)\n",
        "        total_epoch += 128\n",
        "        \n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            print('[%d, %5d] loss: %.7f accuracy: [%d, %d] (%d %%)' % (epoch + 1, i + 1, running_loss / 200, correct, total, 100*correct/total))\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            #print('Epoch: {}   loss: {}  accuracy: {}'.format(epoch,loss,(correct/total)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1,   200] loss: 2.2302093 accuracy: [5539, 25600] (21 %)\n",
            "[2,   200] loss: 2.1473030 accuracy: [7865, 25600] (30 %)\n",
            "[3,   200] loss: 2.0869989 accuracy: [9421, 25600] (36 %)\n",
            "[4,   200] loss: 2.0507557 accuracy: [10368, 25600] (40 %)\n",
            "[5,   200] loss: 2.0049857 accuracy: [11570, 25600] (45 %)\n",
            "[6,   200] loss: 1.9676739 accuracy: [12551, 25600] (49 %)\n",
            "[7,   200] loss: 1.9281547 accuracy: [13546, 25600] (52 %)\n",
            "[8,   200] loss: 1.8856165 accuracy: [14657, 25600] (57 %)\n",
            "[9,   200] loss: 1.8576131 accuracy: [15363, 25600] (60 %)\n",
            "[10,   200] loss: 1.8265894 accuracy: [16185, 25600] (63 %)\n",
            "[11,   200] loss: 1.8015837 accuracy: [16845, 25600] (65 %)\n",
            "[12,   200] loss: 1.7864041 accuracy: [17223, 25600] (67 %)\n",
            "[13,   200] loss: 1.7676317 accuracy: [17729, 25600] (69 %)\n",
            "[14,   200] loss: 1.7489127 accuracy: [18194, 25600] (71 %)\n",
            "[15,   200] loss: 1.7335578 accuracy: [18592, 25600] (72 %)\n",
            "[16,   200] loss: 1.7259925 accuracy: [18795, 25600] (73 %)\n",
            "[17,   200] loss: 1.7134028 accuracy: [19120, 25600] (74 %)\n",
            "[18,   200] loss: 1.7093911 accuracy: [19220, 25600] (75 %)\n",
            "[19,   200] loss: 1.6966306 accuracy: [19556, 25600] (76 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ6FV80IX3z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "running_loss = 0.0\n",
        "correct, total = 0, 0\n",
        "#correct_epoch, total_epoch = 0, 0\n",
        "for i, data in enumerate(testloader):\n",
        "    inp,lab = data[0].to(device),data[1].to(device)\n",
        "    out = model(inp) \n",
        "    c = (torch.argmax(out,1)==lab)\n",
        "    correct+=torch.sum(c)\n",
        "    total += 128\n",
        "    \n",
        "print('accuracy: ',100*correct/total,''%)    "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
