{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPwr26hmysb3sl5ws1W+imc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04150e1f67c84cb9abba7d4925a6d3cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a19c02fcabbe4baaaa8fea4aabe08264",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f5088326d5144a09026aeda57ad5a6c",
              "IPY_MODEL_864b6044fe3f479b8cf9b04256675e0a"
            ]
          }
        },
        "a19c02fcabbe4baaaa8fea4aabe08264": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f5088326d5144a09026aeda57ad5a6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fcb36d5005ad42e59fae3202663c12c1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_272983ee214149e2a8517b34a5c9bc06"
          }
        },
        "864b6044fe3f479b8cf9b04256675e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bd57705054944a2897e4d72235cc38ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:19&lt;00:00, 95982386.99it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_703722d7a9534dd98946e7ef53a65541"
          }
        },
        "fcb36d5005ad42e59fae3202663c12c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "272983ee214149e2a8517b34a5c9bc06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd57705054944a2897e4d72235cc38ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "703722d7a9534dd98946e7ef53a65541": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush12gupta/CNN_models/blob/master/ResNet/ResNet101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wdoSeW-NXXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muKii7CzN3Sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class block(nn.Module):\n",
        "    def __init__(self, inp, out, strides=1):\n",
        "      super().__init__()\n",
        "\n",
        "      self.conv1 = nn.Conv2d(inp, out, 3, padding=1, stride=strides, bias=False)\n",
        "      self.bn1 = nn.BatchNorm2d(out)\n",
        "      self.conv2 = nn.Conv2d(out, out, 3, padding=1, bias=False) # For same size of layer as the previour one\n",
        "      self.bn2 = nn.BatchNorm2d(out)\n",
        "\n",
        "      self.shortcut = nn.Sequential()\n",
        "      if strides!=1 or inp!=out:\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(inp, out,1,stride = strides,bias=False),\n",
        "            nn.BatchNorm2d(out)\n",
        "        )\n",
        "\n",
        "    def forward(self,x):\n",
        "        iden = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += self.shortcut(iden)  # Making identity connection\n",
        "        \n",
        "        return F.relu(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAZMfUs74bsC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class bottleneck(nn.Module):\n",
        "  def __init__(self, inp, out, strides=1):\n",
        "    super().__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(inp, out,1, stride=1,bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out)\n",
        "    self.conv2 = nn.Conv2d(out, out, 3, stride=strides, padding=1, bias=False) \n",
        "    self.bn2 = nn.BatchNorm2d(out)\n",
        "    self.conv3 = nn.Conv2d(out, 4*out, 1, stride=1,bias=False)\n",
        "    self.bn3 = nn.BatchNorm2d(4*out)\n",
        "    \n",
        "    self.shortcut = nn.Sequential()\n",
        "    if strides!=1 or inp!=out*4:\n",
        "        self.shortcut = nn.Sequential(\n",
        "            nn.Conv2d(inp, out*4,1,stride = strides,bias=False),\n",
        "            nn.BatchNorm2d(out*4)\n",
        "        )\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "      iden = x\n",
        "      x = F.relu(self.bn1(self.conv1(x)))\n",
        "      x = F.relu(self.bn2(self.conv2(x)))\n",
        "      x = self.bn3(self.conv3(x))\n",
        "      #print(x.shape,\" s \",self.shortcut(iden).shape)\n",
        "      x += self.shortcut(iden)\n",
        "\n",
        "      return F.relu(x) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZGKSHE0184G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, n,classnum=10):\n",
        "\n",
        "        super().__init__()\n",
        "        if block==bottleneck:\n",
        "          self.exp=4\n",
        "        if block==block:\n",
        "          self.exp=1  \n",
        "        self.inp = 64\n",
        "        self.cov1 = nn.Conv2d(3, 64, 3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.cb1 = self.covBlock(block, 64,n[0],stride=1)\n",
        "        self.cb2 = self.covBlock(block, 128,n[1],stride=2)\n",
        "        self.cb3 = self.covBlock(block, 256,n[2],stride=2)\n",
        "        self.cb4 = self.covBlock(block, 512,n[3],stride=2)\n",
        "        self.fc = nn.Linear(512*self.exp, classnum)\n",
        "\n",
        "    def covBlock(self,block,out,n,stride):\n",
        "\n",
        "        # if stride!=1:\n",
        "        #   inp,out = size\n",
        "        # else:\n",
        "        #   inp,out = size,size\n",
        "\n",
        "        layer = []\n",
        "        layer.append(block(self.inp,out,stride))\n",
        "        self.inp = out*self.exp\n",
        "        #self.inp = self.inp*4\n",
        "        for i in range(n-1):\n",
        "          layer.append(block(self.inp,out))\n",
        "          self.inp = out*self.exp\n",
        "        cb = nn.Sequential(*layer)\n",
        "        return cb  \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = F.relu(self.bn1(self.cov1(x))) \n",
        "        x = self.cb1(x)\n",
        "        x = self.cb2(x)\n",
        "        x = self.cb3(x)\n",
        "        x = self.cb4(x)\n",
        "        x = F.avg_pool2d(x, 4)\n",
        "        x = x.view(x.size(0), -1)  \n",
        "        # x = self.avgpool(x)\n",
        "\n",
        "        # x = x.view(-1, res)\n",
        "        x = self.fc(x)\n",
        "        x = F.softmax(x,dim=1)\n",
        "\n",
        "        return x            "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH7sCtXiwGLh",
        "colab_type": "code",
        "outputId": "9cae08c6-5ad2-479c-f13c-6f81ef0120c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = ResNet(bottleneck,[3,4,24,3])\n",
        "print(model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (cov1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (cb1): Sequential(\n",
            "    (0): bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cb2): Sequential(\n",
            "    (0): bottleneck(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(64, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): bottleneck(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): bottleneck(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): bottleneck(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cb3): Sequential(\n",
            "    (0): bottleneck(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(128, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (3): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (4): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (5): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (6): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (7): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (8): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (9): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (10): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (11): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (12): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (13): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (14): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (15): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (16): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (17): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (18): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (19): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (20): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (21): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (22): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (23): bottleneck(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (cb4): Sequential(\n",
            "    (0): bottleneck(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): bottleneck(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (2): bottleneck(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjCMCapX8GDO",
        "colab_type": "code",
        "outputId": "bd786bfb-9fb8-4aca-b64a-b0751e3d1cbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102,
          "referenced_widgets": [
            "04150e1f67c84cb9abba7d4925a6d3cd",
            "a19c02fcabbe4baaaa8fea4aabe08264",
            "3f5088326d5144a09026aeda57ad5a6c",
            "864b6044fe3f479b8cf9b04256675e0a",
            "fcb36d5005ad42e59fae3202663c12c1",
            "272983ee214149e2a8517b34a5c9bc06",
            "bd57705054944a2897e4d72235cc38ad",
            "703722d7a9534dd98946e7ef53a65541"
          ]
        }
      },
      "source": [
        "batch_size = 64\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((.5, .5, .5), (.5, .5, .5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root = './data', download = True, train = True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root = './data', download = True, train = False, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = True, num_workers=2) # num workers is used to pre process data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "04150e1f67c84cb9abba7d4925a6d3cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHmVMBVrXlI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = ResNet(bottleneck, [3,4,24,3]).cuda() #ResNet101\n",
        "model = ResNet(block, [3,4,6,3]).cuda()\n",
        "learning_rate = 0.01\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate,weight_decay=0.0001)\n",
        "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,50,70,80], gamma=0.1)\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFatoDydX0gs",
        "colab_type": "code",
        "outputId": "878879f9-9391-409a-a1c8-c0a617ac5589",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.train()\n",
        "print('Training Started')\n",
        "losses = []\n",
        "for epoch in range(100):\n",
        "\n",
        "    Tloss,losss = 0., 0.\n",
        "    correct, total = 0., 0.\n",
        "    correct_epoch, total_epoch = 0., 0.\n",
        "    scheduler.step()\n",
        "    for i,data in enumerate(trainloader):\n",
        "\n",
        "        inp,lab = data[0].to(device),data[1].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        out = model(inp)\n",
        "        loss = criterion(out,lab)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        Tloss += loss.item()\n",
        "        losss += loss.item()\n",
        "        c = (torch.argmax(out,1)==lab)\n",
        "        correct+=torch.sum(c)\n",
        "        total += batch_size\n",
        "        correct_epoch += torch.sum(c)\n",
        "        total_epoch += batch_size\n",
        "        \n",
        "        if i % 200 == 199:    # print every 200 mini-batches\n",
        "            #print('[%d, %5d] loss: %.7f accuracy: [%d, %d] (%d %%)' % (epoch + 1, i + 1, running_loss / 200, correct, total, 100*correct/total))\n",
        "            print('Epoch: %d   loss: %.5f  accuracy: %d / %d (%.3f %%)'%(epoch+1,Tloss/200,correct,total,(correct/total)*100))\n",
        "            correct = 0.\n",
        "            total = 0.\n",
        "            Tloss = 0.\n",
        "    print('Epoch: %d Completed !!!! accuracy: %d / %d (%.3f %%)'%(epoch+1,correct_epoch,total_epoch,(correct_epoch/total_epoch)*100))\n",
        "    losses.append(correct_epoch/total_epoch)    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Started\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:123: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1   loss: 2.25626  accuracy: 2333 / 12800 (18.227 %)\n",
            "Epoch: 1   loss: 2.21057  accuracy: 3064 / 12800 (23.938 %)\n",
            "Epoch: 1   loss: 2.19398  accuracy: 3291 / 12800 (25.711 %)\n",
            "Epoch: 1 Completed !!!! accuracy: 3299 / 11648 (23.951 %)\n",
            "Epoch: 2   loss: 2.14272  accuracy: 3972 / 12800 (31.031 %)\n",
            "Epoch: 2   loss: 2.11982  accuracy: 4270 / 12800 (33.359 %)\n",
            "Epoch: 2   loss: 2.09444  accuracy: 4627 / 12800 (36.148 %)\n",
            "Epoch: 2 Completed !!!! accuracy: 4322 / 11648 (34.349 %)\n",
            "Epoch: 3   loss: 2.07471  accuracy: 4846 / 12800 (37.859 %)\n",
            "Epoch: 3   loss: 2.10036  accuracy: 4537 / 12800 (35.445 %)\n",
            "Epoch: 3   loss: 2.08959  accuracy: 4674 / 12800 (36.516 %)\n",
            "Epoch: 3 Completed !!!! accuracy: 4520 / 11648 (37.118 %)\n",
            "Epoch: 4   loss: 2.05769  accuracy: 5056 / 12800 (39.500 %)\n",
            "Epoch: 4   loss: 2.04345  accuracy: 5288 / 12800 (41.312 %)\n",
            "Epoch: 4   loss: 2.03516  accuracy: 5357 / 12800 (41.852 %)\n",
            "Epoch: 4 Completed !!!! accuracy: 5011 / 11648 (41.384 %)\n",
            "Epoch: 5   loss: 2.02186  accuracy: 5532 / 12800 (43.219 %)\n",
            "Epoch: 5   loss: 2.00220  accuracy: 5807 / 12800 (45.367 %)\n",
            "Epoch: 5   loss: 1.99687  accuracy: 5866 / 12800 (45.828 %)\n",
            "Epoch: 5 Completed !!!! accuracy: 5437 / 11648 (45.241 %)\n",
            "Epoch: 6   loss: 1.96535  accuracy: 6288 / 12800 (49.125 %)\n",
            "Epoch: 6   loss: 1.95263  accuracy: 6450 / 12800 (50.391 %)\n",
            "Epoch: 6   loss: 1.95542  accuracy: 6427 / 12800 (50.211 %)\n",
            "Epoch: 6 Completed !!!! accuracy: 6041 / 11648 (50.364 %)\n",
            "Epoch: 7   loss: 1.91010  accuracy: 7003 / 12800 (54.711 %)\n",
            "Epoch: 7   loss: 1.90713  accuracy: 7044 / 12800 (55.031 %)\n",
            "Epoch: 7   loss: 1.90946  accuracy: 7007 / 12800 (54.742 %)\n",
            "Epoch: 7 Completed !!!! accuracy: 6416 / 11648 (54.887 %)\n",
            "Epoch: 8   loss: 1.87914  accuracy: 7399 / 12800 (57.805 %)\n",
            "Epoch: 8   loss: 1.88635  accuracy: 7288 / 12800 (56.937 %)\n",
            "Epoch: 8   loss: 1.87021  accuracy: 7513 / 12800 (58.695 %)\n",
            "Epoch: 8 Completed !!!! accuracy: 6897 / 11648 (58.138 %)\n",
            "Epoch: 9   loss: 1.84344  accuracy: 7869 / 12800 (61.477 %)\n",
            "Epoch: 9   loss: 1.84373  accuracy: 7880 / 12800 (61.562 %)\n",
            "Epoch: 9   loss: 1.84612  accuracy: 7818 / 12800 (61.078 %)\n",
            "Epoch: 9 Completed !!!! accuracy: 7249 / 11648 (61.573 %)\n",
            "Epoch: 10   loss: 1.81476  accuracy: 8242 / 12800 (64.391 %)\n",
            "Epoch: 10   loss: 1.81556  accuracy: 8224 / 12800 (64.250 %)\n",
            "Epoch: 10   loss: 1.80889  accuracy: 8321 / 12800 (65.008 %)\n",
            "Epoch: 10 Completed !!!! accuracy: 7552 / 11648 (64.616 %)\n",
            "Epoch: 11   loss: 1.79275  accuracy: 8543 / 12800 (66.742 %)\n",
            "Epoch: 11   loss: 1.79507  accuracy: 8490 / 12800 (66.328 %)\n",
            "Epoch: 11   loss: 1.78978  accuracy: 8571 / 12800 (66.961 %)\n",
            "Epoch: 11 Completed !!!! accuracy: 7798 / 11648 (66.740 %)\n",
            "Epoch: 12   loss: 1.77732  accuracy: 8730 / 12800 (68.203 %)\n",
            "Epoch: 12   loss: 1.77030  accuracy: 8810 / 12800 (68.828 %)\n",
            "Epoch: 12   loss: 1.76278  accuracy: 8899 / 12800 (69.523 %)\n",
            "Epoch: 12 Completed !!!! accuracy: 8059 / 11648 (68.930 %)\n",
            "Epoch: 13   loss: 1.75421  accuracy: 9057 / 12800 (70.758 %)\n",
            "Epoch: 13   loss: 1.75164  accuracy: 9068 / 12800 (70.844 %)\n",
            "Epoch: 13   loss: 1.75106  accuracy: 9077 / 12800 (70.914 %)\n",
            "Epoch: 13 Completed !!!! accuracy: 8299 / 11648 (70.934 %)\n",
            "Epoch: 14   loss: 1.72857  accuracy: 9361 / 12800 (73.133 %)\n",
            "Epoch: 14   loss: 1.73771  accuracy: 9230 / 12800 (72.109 %)\n",
            "Epoch: 14   loss: 1.73273  accuracy: 9300 / 12800 (72.656 %)\n",
            "Epoch: 14 Completed !!!! accuracy: 8507 / 11648 (72.726 %)\n",
            "Epoch: 15   loss: 1.71121  accuracy: 9588 / 12800 (74.906 %)\n",
            "Epoch: 15   loss: 1.71489  accuracy: 9545 / 12800 (74.570 %)\n",
            "Epoch: 15   loss: 1.71150  accuracy: 9568 / 12800 (74.750 %)\n",
            "Epoch: 15 Completed !!!! accuracy: 8623 / 11648 (74.576 %)\n",
            "Epoch: 16   loss: 1.70283  accuracy: 9697 / 12800 (75.758 %)\n",
            "Epoch: 16   loss: 1.69789  accuracy: 9753 / 12800 (76.195 %)\n",
            "Epoch: 16   loss: 1.69226  accuracy: 9831 / 12800 (76.805 %)\n",
            "Epoch: 16 Completed !!!! accuracy: 8823 / 11648 (76.135 %)\n",
            "Epoch: 17   loss: 1.68825  accuracy: 9879 / 12800 (77.180 %)\n",
            "Epoch: 17   loss: 1.68238  accuracy: 9950 / 12800 (77.734 %)\n",
            "Epoch: 17   loss: 1.69143  accuracy: 9842 / 12800 (76.891 %)\n",
            "Epoch: 17 Completed !!!! accuracy: 8961 / 11648 (77.190 %)\n",
            "Epoch: 18   loss: 1.66669  accuracy: 10158 / 12800 (79.359 %)\n",
            "Epoch: 18   loss: 1.67000  accuracy: 10113 / 12800 (79.008 %)\n",
            "Epoch: 18   loss: 1.67115  accuracy: 10105 / 12800 (78.945 %)\n",
            "Epoch: 18 Completed !!!! accuracy: 9028 / 11648 (78.732 %)\n",
            "Epoch: 19   loss: 1.65583  accuracy: 10296 / 12800 (80.438 %)\n",
            "Epoch: 19   loss: 1.66125  accuracy: 10233 / 12800 (79.945 %)\n",
            "Epoch: 19   loss: 1.65985  accuracy: 10256 / 12800 (80.125 %)\n",
            "Epoch: 19 Completed !!!! accuracy: 9256 / 11648 (80.005 %)\n",
            "Epoch: 20   loss: 1.64772  accuracy: 10405 / 12800 (81.289 %)\n",
            "Epoch: 20   loss: 1.65199  accuracy: 10346 / 12800 (80.828 %)\n",
            "Epoch: 20   loss: 1.65564  accuracy: 10315 / 12800 (80.586 %)\n",
            "Epoch: 20 Completed !!!! accuracy: 9335 / 11648 (80.725 %)\n",
            "Epoch: 21   loss: 1.64615  accuracy: 10420 / 12800 (81.406 %)\n",
            "Epoch: 21   loss: 1.64686  accuracy: 10422 / 12800 (81.422 %)\n",
            "Epoch: 21   loss: 1.64747  accuracy: 10408 / 12800 (81.312 %)\n",
            "Epoch: 21 Completed !!!! accuracy: 9511 / 11648 (81.444 %)\n",
            "Epoch: 22   loss: 1.62666  accuracy: 10672 / 12800 (83.375 %)\n",
            "Epoch: 22   loss: 1.63155  accuracy: 10616 / 12800 (82.938 %)\n",
            "Epoch: 22   loss: 1.63189  accuracy: 10600 / 12800 (82.812 %)\n",
            "Epoch: 22 Completed !!!! accuracy: 9503 / 11648 (82.703 %)\n",
            "Epoch: 23   loss: 1.62464  accuracy: 10695 / 12800 (83.555 %)\n",
            "Epoch: 23   loss: 1.62518  accuracy: 10706 / 12800 (83.641 %)\n",
            "Epoch: 23   loss: 1.62523  accuracy: 10691 / 12800 (83.523 %)\n",
            "Epoch: 23 Completed !!!! accuracy: 9662 / 11648 (83.428 %)\n",
            "Epoch: 24   loss: 1.61007  accuracy: 10890 / 12800 (85.078 %)\n",
            "Epoch: 24   loss: 1.61976  accuracy: 10777 / 12800 (84.195 %)\n",
            "Epoch: 24   loss: 1.61641  accuracy: 10812 / 12800 (84.469 %)\n",
            "Epoch: 24 Completed !!!! accuracy: 9702 / 11648 (84.281 %)\n",
            "Epoch: 25   loss: 1.60903  accuracy: 10908 / 12800 (85.219 %)\n",
            "Epoch: 25   loss: 1.61368  accuracy: 10838 / 12800 (84.672 %)\n",
            "Epoch: 25   loss: 1.61556  accuracy: 10815 / 12800 (84.492 %)\n",
            "Epoch: 25 Completed !!!! accuracy: 9820 / 11648 (84.681 %)\n",
            "Epoch: 26   loss: 1.60728  accuracy: 10926 / 12800 (85.359 %)\n",
            "Epoch: 26   loss: 1.61220  accuracy: 10859 / 12800 (84.836 %)\n",
            "Epoch: 26   loss: 1.59762  accuracy: 11057 / 12800 (86.383 %)\n",
            "Epoch: 26 Completed !!!! accuracy: 9903 / 11648 (85.408 %)\n",
            "Epoch: 27   loss: 1.59359  accuracy: 11104 / 12800 (86.750 %)\n",
            "Epoch: 27   loss: 1.59492  accuracy: 11092 / 12800 (86.656 %)\n",
            "Epoch: 27   loss: 1.60274  accuracy: 10990 / 12800 (85.859 %)\n",
            "Epoch: 27 Completed !!!! accuracy: 9966 / 11648 (86.221 %)\n",
            "Epoch: 28   loss: 1.58808  accuracy: 11178 / 12800 (87.328 %)\n",
            "Epoch: 28   loss: 1.59458  accuracy: 11097 / 12800 (86.695 %)\n",
            "Epoch: 28   loss: 1.59439  accuracy: 11096 / 12800 (86.688 %)\n",
            "Epoch: 28 Completed !!!! accuracy: 10055 / 11648 (86.769 %)\n",
            "Epoch: 29   loss: 1.58039  accuracy: 11257 / 12800 (87.945 %)\n",
            "Epoch: 29   loss: 1.58450  accuracy: 11216 / 12800 (87.625 %)\n",
            "Epoch: 29   loss: 1.58982  accuracy: 11146 / 12800 (87.078 %)\n",
            "Epoch: 29 Completed !!!! accuracy: 10076 / 11648 (87.306 %)\n",
            "Epoch: 30   loss: 1.57405  accuracy: 11358 / 12800 (88.734 %)\n",
            "Epoch: 30   loss: 1.56536  accuracy: 11469 / 12800 (89.602 %)\n",
            "Epoch: 30   loss: 1.56031  accuracy: 11527 / 12800 (90.055 %)\n",
            "Epoch: 30 Completed !!!! accuracy: 10487 / 11648 (89.596 %)\n",
            "Epoch: 31   loss: 1.55440  accuracy: 11611 / 12800 (90.711 %)\n",
            "Epoch: 31   loss: 1.54684  accuracy: 11707 / 12800 (91.461 %)\n",
            "Epoch: 31   loss: 1.55358  accuracy: 11618 / 12800 (90.766 %)\n",
            "Epoch: 31 Completed !!!! accuracy: 10567 / 11648 (90.919 %)\n",
            "Epoch: 32   loss: 1.54675  accuracy: 11700 / 12800 (91.406 %)\n",
            "Epoch: 32   loss: 1.54330  accuracy: 11752 / 12800 (91.812 %)\n",
            "Epoch: 32   loss: 1.54307  accuracy: 11758 / 12800 (91.859 %)\n",
            "Epoch: 32 Completed !!!! accuracy: 10612 / 11648 (91.556 %)\n",
            "Epoch: 33   loss: 1.53760  accuracy: 11826 / 12800 (92.391 %)\n",
            "Epoch: 33   loss: 1.53878  accuracy: 11810 / 12800 (92.266 %)\n",
            "Epoch: 33   loss: 1.54194  accuracy: 11775 / 12800 (91.992 %)\n",
            "Epoch: 33 Completed !!!! accuracy: 10685 / 11648 (92.104 %)\n",
            "Epoch: 34   loss: 1.53839  accuracy: 11811 / 12800 (92.273 %)\n",
            "Epoch: 34   loss: 1.53662  accuracy: 11835 / 12800 (92.461 %)\n",
            "Epoch: 34   loss: 1.53844  accuracy: 11813 / 12800 (92.289 %)\n",
            "Epoch: 34 Completed !!!! accuracy: 10748 / 11648 (92.325 %)\n",
            "Epoch: 35   loss: 1.53463  accuracy: 11862 / 12800 (92.672 %)\n",
            "Epoch: 35   loss: 1.53618  accuracy: 11848 / 12800 (92.562 %)\n",
            "Epoch: 35   loss: 1.53330  accuracy: 11876 / 12800 (92.781 %)\n",
            "Epoch: 35 Completed !!!! accuracy: 10769 / 11648 (92.621 %)\n",
            "Epoch: 36   loss: 1.53249  accuracy: 11893 / 12800 (92.914 %)\n",
            "Epoch: 36   loss: 1.52680  accuracy: 11967 / 12800 (93.492 %)\n",
            "Epoch: 36   loss: 1.53456  accuracy: 11868 / 12800 (92.719 %)\n",
            "Epoch: 36 Completed !!!! accuracy: 10775 / 11648 (92.917 %)\n",
            "Epoch: 37   loss: 1.53174  accuracy: 11900 / 12800 (92.969 %)\n",
            "Epoch: 37   loss: 1.53025  accuracy: 11919 / 12800 (93.117 %)\n",
            "Epoch: 37   loss: 1.52484  accuracy: 11990 / 12800 (93.672 %)\n",
            "Epoch: 37 Completed !!!! accuracy: 10818 / 11648 (93.165 %)\n",
            "Epoch: 38   loss: 1.52600  accuracy: 11974 / 12800 (93.547 %)\n",
            "Epoch: 38   loss: 1.52746  accuracy: 11958 / 12800 (93.422 %)\n",
            "Epoch: 38   loss: 1.52992  accuracy: 11925 / 12800 (93.164 %)\n",
            "Epoch: 38 Completed !!!! accuracy: 10835 / 11648 (93.294 %)\n",
            "Epoch: 39   loss: 1.52625  accuracy: 11967 / 12800 (93.492 %)\n",
            "Epoch: 39   loss: 1.52670  accuracy: 11965 / 12800 (93.477 %)\n",
            "Epoch: 39   loss: 1.52650  accuracy: 11964 / 12800 (93.469 %)\n",
            "Epoch: 39 Completed !!!! accuracy: 10852 / 11648 (93.406 %)\n",
            "Epoch: 40   loss: 1.52393  accuracy: 12008 / 12800 (93.812 %)\n",
            "Epoch: 40   loss: 1.52462  accuracy: 11994 / 12800 (93.703 %)\n",
            "Epoch: 40   loss: 1.52410  accuracy: 12002 / 12800 (93.766 %)\n",
            "Epoch: 40 Completed !!!! accuracy: 10872 / 11648 (93.662 %)\n",
            "Epoch: 41   loss: 1.52345  accuracy: 12008 / 12800 (93.812 %)\n",
            "Epoch: 41   loss: 1.52503  accuracy: 11986 / 12800 (93.641 %)\n",
            "Epoch: 41   loss: 1.52127  accuracy: 12038 / 12800 (94.047 %)\n",
            "Epoch: 41 Completed !!!! accuracy: 10907 / 11648 (93.788 %)\n",
            "Epoch: 42   loss: 1.52031  accuracy: 12041 / 12800 (94.070 %)\n",
            "Epoch: 42   loss: 1.52096  accuracy: 12037 / 12800 (94.039 %)\n",
            "Epoch: 42   loss: 1.52085  accuracy: 12045 / 12800 (94.102 %)\n",
            "Epoch: 42 Completed !!!! accuracy: 10851 / 11648 (93.858 %)\n",
            "Epoch: 43   loss: 1.52107  accuracy: 12034 / 12800 (94.016 %)\n",
            "Epoch: 43   loss: 1.51780  accuracy: 12078 / 12800 (94.359 %)\n",
            "Epoch: 43   loss: 1.52282  accuracy: 12015 / 12800 (93.867 %)\n",
            "Epoch: 43 Completed !!!! accuracy: 10931 / 11648 (94.026 %)\n",
            "Epoch: 44   loss: 1.51985  accuracy: 12052 / 12800 (94.156 %)\n",
            "Epoch: 44   loss: 1.51853  accuracy: 12067 / 12800 (94.273 %)\n",
            "Epoch: 44   loss: 1.51668  accuracy: 12093 / 12800 (94.477 %)\n",
            "Epoch: 44 Completed !!!! accuracy: 10887 / 11648 (94.108 %)\n",
            "Epoch: 45   loss: 1.51829  accuracy: 12070 / 12800 (94.297 %)\n",
            "Epoch: 45   loss: 1.51767  accuracy: 12081 / 12800 (94.383 %)\n",
            "Epoch: 45   loss: 1.51721  accuracy: 12088 / 12800 (94.438 %)\n",
            "Epoch: 45 Completed !!!! accuracy: 10910 / 11648 (94.208 %)\n",
            "Epoch: 46   loss: 1.51677  accuracy: 12091 / 12800 (94.461 %)\n",
            "Epoch: 46   loss: 1.51801  accuracy: 12077 / 12800 (94.352 %)\n",
            "Epoch: 46   loss: 1.51677  accuracy: 12094 / 12800 (94.484 %)\n",
            "Epoch: 46 Completed !!!! accuracy: 10958 / 11648 (94.349 %)\n",
            "Epoch: 47   loss: 1.51649  accuracy: 12100 / 12800 (94.531 %)\n",
            "Epoch: 47   loss: 1.51592  accuracy: 12103 / 12800 (94.555 %)\n",
            "Epoch: 47   loss: 1.51589  accuracy: 12102 / 12800 (94.547 %)\n",
            "Epoch: 47 Completed !!!! accuracy: 10962 / 11648 (94.443 %)\n",
            "Epoch: 48   loss: 1.51629  accuracy: 12098 / 12800 (94.516 %)\n",
            "Epoch: 48   loss: 1.51499  accuracy: 12115 / 12800 (94.648 %)\n",
            "Epoch: 48   loss: 1.51371  accuracy: 12134 / 12800 (94.797 %)\n",
            "Epoch: 48 Completed !!!! accuracy: 10949 / 11648 (94.501 %)\n",
            "Epoch: 49   loss: 1.51065  accuracy: 12167 / 12800 (95.055 %)\n",
            "Epoch: 49   loss: 1.51505  accuracy: 12118 / 12800 (94.672 %)\n",
            "Epoch: 49   loss: 1.51587  accuracy: 12102 / 12800 (94.547 %)\n",
            "Epoch: 49 Completed !!!! accuracy: 10959 / 11648 (94.601 %)\n",
            "Epoch: 50   loss: 1.51515  accuracy: 12112 / 12800 (94.625 %)\n",
            "Epoch: 50   loss: 1.51342  accuracy: 12134 / 12800 (94.797 %)\n",
            "Epoch: 50   loss: 1.51251  accuracy: 12146 / 12800 (94.891 %)\n",
            "Epoch: 50 Completed !!!! accuracy: 11002 / 11648 (94.697 %)\n",
            "Epoch: 51   loss: 1.51109  accuracy: 12162 / 12800 (95.016 %)\n",
            "Epoch: 51   loss: 1.51520  accuracy: 12111 / 12800 (94.617 %)\n",
            "Epoch: 51   loss: 1.51005  accuracy: 12178 / 12800 (95.141 %)\n",
            "Epoch: 51 Completed !!!! accuracy: 10961 / 11648 (94.733 %)\n",
            "Epoch: 52   loss: 1.51205  accuracy: 12151 / 12800 (94.930 %)\n",
            "Epoch: 52   loss: 1.51280  accuracy: 12141 / 12800 (94.852 %)\n",
            "Epoch: 52   loss: 1.51340  accuracy: 12132 / 12800 (94.781 %)\n",
            "Epoch: 52 Completed !!!! accuracy: 10998 / 11648 (94.753 %)\n",
            "Epoch: 53   loss: 1.51373  accuracy: 12126 / 12800 (94.734 %)\n",
            "Epoch: 53   loss: 1.51302  accuracy: 12137 / 12800 (94.820 %)\n",
            "Epoch: 53   loss: 1.51223  accuracy: 12148 / 12800 (94.906 %)\n",
            "Epoch: 53 Completed !!!! accuracy: 11006 / 11648 (94.743 %)\n",
            "Epoch: 54   loss: 1.51427  accuracy: 12122 / 12800 (94.703 %)\n",
            "Epoch: 54   loss: 1.51415  accuracy: 12123 / 12800 (94.711 %)\n",
            "Epoch: 54   loss: 1.50960  accuracy: 12180 / 12800 (95.156 %)\n",
            "Epoch: 54 Completed !!!! accuracy: 10987 / 11648 (94.733 %)\n",
            "Epoch: 55   loss: 1.51286  accuracy: 12137 / 12800 (94.820 %)\n",
            "Epoch: 55   loss: 1.51387  accuracy: 12125 / 12800 (94.727 %)\n",
            "Epoch: 55   loss: 1.51241  accuracy: 12144 / 12800 (94.875 %)\n",
            "Epoch: 55 Completed !!!! accuracy: 11018 / 11648 (94.757 %)\n",
            "Epoch: 56   loss: 1.51254  accuracy: 12144 / 12800 (94.875 %)\n",
            "Epoch: 56   loss: 1.51447  accuracy: 12118 / 12800 (94.672 %)\n",
            "Epoch: 56   loss: 1.51192  accuracy: 12152 / 12800 (94.938 %)\n",
            "Epoch: 56 Completed !!!! accuracy: 11018 / 11648 (94.773 %)\n",
            "Epoch: 57   loss: 1.51069  accuracy: 12169 / 12800 (95.070 %)\n",
            "Epoch: 57   loss: 1.51190  accuracy: 12154 / 12800 (94.953 %)\n",
            "Epoch: 57   loss: 1.51289  accuracy: 12138 / 12800 (94.828 %)\n",
            "Epoch: 57 Completed !!!! accuracy: 10993 / 11648 (94.817 %)\n",
            "Epoch: 58   loss: 1.51083  accuracy: 12168 / 12800 (95.062 %)\n",
            "Epoch: 58   loss: 1.51351  accuracy: 12131 / 12800 (94.773 %)\n",
            "Epoch: 58   loss: 1.51155  accuracy: 12156 / 12800 (94.969 %)\n",
            "Epoch: 58 Completed !!!! accuracy: 11006 / 11648 (94.831 %)\n",
            "Epoch: 59   loss: 1.51494  accuracy: 12112 / 12800 (94.625 %)\n",
            "Epoch: 59   loss: 1.51411  accuracy: 12121 / 12800 (94.695 %)\n",
            "Epoch: 59   loss: 1.51082  accuracy: 12166 / 12800 (95.047 %)\n",
            "Epoch: 59 Completed !!!! accuracy: 11061 / 11648 (94.829 %)\n",
            "Epoch: 60   loss: 1.51092  accuracy: 12162 / 12800 (95.016 %)\n",
            "Epoch: 60   loss: 1.51482  accuracy: 12112 / 12800 (94.625 %)\n",
            "Epoch: 60   loss: 1.51264  accuracy: 12141 / 12800 (94.852 %)\n",
            "Epoch: 60 Completed !!!! accuracy: 11044 / 11648 (94.827 %)\n",
            "Epoch: 61   loss: 1.51228  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 61   loss: 1.51183  accuracy: 12152 / 12800 (94.938 %)\n",
            "Epoch: 61   loss: 1.51290  accuracy: 12136 / 12800 (94.812 %)\n",
            "Epoch: 61 Completed !!!! accuracy: 11018 / 11648 (94.811 %)\n",
            "Epoch: 62   loss: 1.51237  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 62   loss: 1.51415  accuracy: 12121 / 12800 (94.695 %)\n",
            "Epoch: 62   loss: 1.51162  accuracy: 12154 / 12800 (94.953 %)\n",
            "Epoch: 62 Completed !!!! accuracy: 11035 / 11648 (94.819 %)\n",
            "Epoch: 63   loss: 1.51111  accuracy: 12161 / 12800 (95.008 %)\n",
            "Epoch: 63   loss: 1.51073  accuracy: 12164 / 12800 (95.031 %)\n",
            "Epoch: 63   loss: 1.51255  accuracy: 12144 / 12800 (94.875 %)\n",
            "Epoch: 63 Completed !!!! accuracy: 11013 / 11648 (94.873 %)\n",
            "Epoch: 64   loss: 1.51233  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 64   loss: 1.51223  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 64   loss: 1.51265  accuracy: 12141 / 12800 (94.852 %)\n",
            "Epoch: 64 Completed !!!! accuracy: 11043 / 11648 (94.857 %)\n",
            "Epoch: 65   loss: 1.51273  accuracy: 12140 / 12800 (94.844 %)\n",
            "Epoch: 65   loss: 1.51128  accuracy: 12158 / 12800 (94.984 %)\n",
            "Epoch: 65   loss: 1.51369  accuracy: 12127 / 12800 (94.742 %)\n",
            "Epoch: 65 Completed !!!! accuracy: 11043 / 11648 (94.845 %)\n",
            "Epoch: 66   loss: 1.51010  accuracy: 12175 / 12800 (95.117 %)\n",
            "Epoch: 66   loss: 1.51156  accuracy: 12158 / 12800 (94.984 %)\n",
            "Epoch: 66   loss: 1.51260  accuracy: 12144 / 12800 (94.875 %)\n",
            "Epoch: 66 Completed !!!! accuracy: 11015 / 11648 (94.893 %)\n",
            "Epoch: 67   loss: 1.50953  accuracy: 12181 / 12800 (95.164 %)\n",
            "Epoch: 67   loss: 1.51397  accuracy: 12127 / 12800 (94.742 %)\n",
            "Epoch: 67   loss: 1.51141  accuracy: 12157 / 12800 (94.977 %)\n",
            "Epoch: 67 Completed !!!! accuracy: 11027 / 11648 (94.893 %)\n",
            "Epoch: 68   loss: 1.51211  accuracy: 12150 / 12800 (94.922 %)\n",
            "Epoch: 68   loss: 1.50786  accuracy: 12205 / 12800 (95.352 %)\n",
            "Epoch: 68   loss: 1.51182  accuracy: 12154 / 12800 (94.953 %)\n",
            "Epoch: 68 Completed !!!! accuracy: 11001 / 11648 (94.929 %)\n",
            "Epoch: 69   loss: 1.51260  accuracy: 12143 / 12800 (94.867 %)\n",
            "Epoch: 69   loss: 1.51099  accuracy: 12161 / 12800 (95.008 %)\n",
            "Epoch: 69   loss: 1.50959  accuracy: 12182 / 12800 (95.172 %)\n",
            "Epoch: 69 Completed !!!! accuracy: 11015 / 11648 (94.911 %)\n",
            "Epoch: 70   loss: 1.51040  accuracy: 12170 / 12800 (95.078 %)\n",
            "Epoch: 70   loss: 1.51298  accuracy: 12138 / 12800 (94.828 %)\n",
            "Epoch: 70   loss: 1.51209  accuracy: 12149 / 12800 (94.914 %)\n",
            "Epoch: 70 Completed !!!! accuracy: 11056 / 11648 (94.935 %)\n",
            "Epoch: 71   loss: 1.50818  accuracy: 12197 / 12800 (95.289 %)\n",
            "Epoch: 71   loss: 1.51080  accuracy: 12166 / 12800 (95.047 %)\n",
            "Epoch: 71   loss: 1.51200  accuracy: 12150 / 12800 (94.922 %)\n",
            "Epoch: 71 Completed !!!! accuracy: 10983 / 11648 (94.901 %)\n",
            "Epoch: 72   loss: 1.51244  accuracy: 12144 / 12800 (94.875 %)\n",
            "Epoch: 72   loss: 1.51205  accuracy: 12147 / 12800 (94.898 %)\n",
            "Epoch: 72   loss: 1.51199  accuracy: 12151 / 12800 (94.930 %)\n",
            "Epoch: 72 Completed !!!! accuracy: 11063 / 11648 (94.919 %)\n",
            "Epoch: 73   loss: 1.51091  accuracy: 12164 / 12800 (95.031 %)\n",
            "Epoch: 73   loss: 1.51231  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 73   loss: 1.51005  accuracy: 12177 / 12800 (95.133 %)\n",
            "Epoch: 73 Completed !!!! accuracy: 11033 / 11648 (94.947 %)\n",
            "Epoch: 74   loss: 1.51048  accuracy: 12168 / 12800 (95.062 %)\n",
            "Epoch: 74   loss: 1.51268  accuracy: 12142 / 12800 (94.859 %)\n",
            "Epoch: 74   loss: 1.50899  accuracy: 12190 / 12800 (95.234 %)\n",
            "Epoch: 74 Completed !!!! accuracy: 11012 / 11648 (94.933 %)\n",
            "Epoch: 75   loss: 1.51251  accuracy: 12143 / 12800 (94.867 %)\n",
            "Epoch: 75   loss: 1.51067  accuracy: 12168 / 12800 (95.062 %)\n",
            "Epoch: 75   loss: 1.50891  accuracy: 12188 / 12800 (95.219 %)\n",
            "Epoch: 75 Completed !!!! accuracy: 11012 / 11648 (94.931 %)\n",
            "Epoch: 76   loss: 1.50897  accuracy: 12187 / 12800 (95.211 %)\n",
            "Epoch: 76   loss: 1.50960  accuracy: 12179 / 12800 (95.148 %)\n",
            "Epoch: 76   loss: 1.51220  accuracy: 12146 / 12800 (94.891 %)\n",
            "Epoch: 76 Completed !!!! accuracy: 10994 / 11648 (94.921 %)\n",
            "Epoch: 77   loss: 1.50833  accuracy: 12195 / 12800 (95.273 %)\n",
            "Epoch: 77   loss: 1.51284  accuracy: 12141 / 12800 (94.852 %)\n",
            "Epoch: 77   loss: 1.51172  accuracy: 12154 / 12800 (94.953 %)\n",
            "Epoch: 77 Completed !!!! accuracy: 11016 / 11648 (94.921 %)\n",
            "Epoch: 78   loss: 1.51067  accuracy: 12166 / 12800 (95.047 %)\n",
            "Epoch: 78   loss: 1.51154  accuracy: 12153 / 12800 (94.945 %)\n",
            "Epoch: 78   loss: 1.51244  accuracy: 12147 / 12800 (94.898 %)\n",
            "Epoch: 78 Completed !!!! accuracy: 11033 / 11648 (94.907 %)\n",
            "Epoch: 79   loss: 1.51173  accuracy: 12153 / 12800 (94.945 %)\n",
            "Epoch: 79   loss: 1.50938  accuracy: 12181 / 12800 (95.164 %)\n",
            "Epoch: 79   loss: 1.51160  accuracy: 12153 / 12800 (94.945 %)\n",
            "Epoch: 79 Completed !!!! accuracy: 11022 / 11648 (94.927 %)\n",
            "Epoch: 80   loss: 1.50977  accuracy: 12177 / 12800 (95.133 %)\n",
            "Epoch: 80   loss: 1.51010  accuracy: 12174 / 12800 (95.109 %)\n",
            "Epoch: 80   loss: 1.51253  accuracy: 12141 / 12800 (94.852 %)\n",
            "Epoch: 80 Completed !!!! accuracy: 11013 / 11648 (94.919 %)\n",
            "Epoch: 81   loss: 1.51124  accuracy: 12158 / 12800 (94.984 %)\n",
            "Epoch: 81   loss: 1.50856  accuracy: 12195 / 12800 (95.273 %)\n",
            "Epoch: 81   loss: 1.51107  accuracy: 12163 / 12800 (95.023 %)\n",
            "Epoch: 81 Completed !!!! accuracy: 11004 / 11648 (94.949 %)\n",
            "Epoch: 82   loss: 1.50829  accuracy: 12197 / 12800 (95.289 %)\n",
            "Epoch: 82   loss: 1.51377  accuracy: 12128 / 12800 (94.750 %)\n",
            "Epoch: 82   loss: 1.51267  accuracy: 12140 / 12800 (94.844 %)\n",
            "Epoch: 82 Completed !!!! accuracy: 11051 / 11648 (94.941 %)\n",
            "Epoch: 83   loss: 1.51281  accuracy: 12139 / 12800 (94.836 %)\n",
            "Epoch: 83   loss: 1.51103  accuracy: 12163 / 12800 (95.023 %)\n",
            "Epoch: 83   loss: 1.51182  accuracy: 12153 / 12800 (94.945 %)\n",
            "Epoch: 83 Completed !!!! accuracy: 11057 / 11648 (94.933 %)\n",
            "Epoch: 84   loss: 1.51208  accuracy: 12150 / 12800 (94.922 %)\n",
            "Epoch: 84   loss: 1.50715  accuracy: 12212 / 12800 (95.406 %)\n",
            "Epoch: 84   loss: 1.51504  accuracy: 12110 / 12800 (94.609 %)\n",
            "Epoch: 84 Completed !!!! accuracy: 11038 / 11648 (94.929 %)\n",
            "Epoch: 85   loss: 1.51237  accuracy: 12144 / 12800 (94.875 %)\n",
            "Epoch: 85   loss: 1.51153  accuracy: 12153 / 12800 (94.945 %)\n",
            "Epoch: 85   loss: 1.50902  accuracy: 12188 / 12800 (95.219 %)\n",
            "Epoch: 85 Completed !!!! accuracy: 11029 / 11648 (94.937 %)\n",
            "Epoch: 86   loss: 1.51143  accuracy: 12158 / 12800 (94.984 %)\n",
            "Epoch: 86   loss: 1.51032  accuracy: 12170 / 12800 (95.078 %)\n",
            "Epoch: 86   loss: 1.50999  accuracy: 12178 / 12800 (95.141 %)\n",
            "Epoch: 86 Completed !!!! accuracy: 11003 / 11648 (94.927 %)\n",
            "Epoch: 87   loss: 1.51231  accuracy: 12146 / 12800 (94.891 %)\n",
            "Epoch: 87   loss: 1.51063  accuracy: 12164 / 12800 (95.031 %)\n",
            "Epoch: 87   loss: 1.51021  accuracy: 12174 / 12800 (95.109 %)\n",
            "Epoch: 87 Completed !!!! accuracy: 11022 / 11648 (94.921 %)\n",
            "Epoch: 88   loss: 1.50958  accuracy: 12180 / 12800 (95.156 %)\n",
            "Epoch: 88   loss: 1.51282  accuracy: 12140 / 12800 (94.844 %)\n",
            "Epoch: 88   loss: 1.51000  accuracy: 12176 / 12800 (95.125 %)\n",
            "Epoch: 88 Completed !!!! accuracy: 11023 / 11648 (94.947 %)\n",
            "Epoch: 89   loss: 1.51084  accuracy: 12166 / 12800 (95.047 %)\n",
            "Epoch: 89   loss: 1.50877  accuracy: 12193 / 12800 (95.258 %)\n",
            "Epoch: 89   loss: 1.51234  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 89 Completed !!!! accuracy: 11020 / 11648 (94.957 %)\n",
            "Epoch: 90   loss: 1.51052  accuracy: 12172 / 12800 (95.094 %)\n",
            "Epoch: 90   loss: 1.51376  accuracy: 12127 / 12800 (94.742 %)\n",
            "Epoch: 90   loss: 1.51036  accuracy: 12170 / 12800 (95.078 %)\n",
            "Epoch: 90 Completed !!!! accuracy: 11045 / 11648 (94.937 %)\n",
            "Epoch: 91   loss: 1.50986  accuracy: 12175 / 12800 (95.117 %)\n",
            "Epoch: 91   loss: 1.51019  accuracy: 12172 / 12800 (95.094 %)\n",
            "Epoch: 91   loss: 1.51295  accuracy: 12135 / 12800 (94.805 %)\n",
            "Epoch: 91 Completed !!!! accuracy: 11025 / 11648 (94.923 %)\n",
            "Epoch: 92   loss: 1.51233  accuracy: 12143 / 12800 (94.867 %)\n",
            "Epoch: 92   loss: 1.50946  accuracy: 12182 / 12800 (95.172 %)\n",
            "Epoch: 92   loss: 1.51067  accuracy: 12165 / 12800 (95.039 %)\n",
            "Epoch: 92 Completed !!!! accuracy: 11019 / 11648 (94.927 %)\n",
            "Epoch: 93   loss: 1.50934  accuracy: 12184 / 12800 (95.188 %)\n",
            "Epoch: 93   loss: 1.51316  accuracy: 12134 / 12800 (94.797 %)\n",
            "Epoch: 93   loss: 1.50916  accuracy: 12185 / 12800 (95.195 %)\n",
            "Epoch: 93 Completed !!!! accuracy: 11005 / 11648 (94.925 %)\n",
            "Epoch: 94   loss: 1.51138  accuracy: 12158 / 12800 (94.984 %)\n",
            "Epoch: 94   loss: 1.51089  accuracy: 12164 / 12800 (95.031 %)\n",
            "Epoch: 94   loss: 1.50965  accuracy: 12177 / 12800 (95.133 %)\n",
            "Epoch: 94 Completed !!!! accuracy: 11019 / 11648 (94.945 %)\n",
            "Epoch: 95   loss: 1.51462  accuracy: 12121 / 12800 (94.695 %)\n",
            "Epoch: 95   loss: 1.50902  accuracy: 12188 / 12800 (95.219 %)\n",
            "Epoch: 95   loss: 1.51013  accuracy: 12170 / 12800 (95.078 %)\n",
            "Epoch: 95 Completed !!!! accuracy: 11034 / 11648 (94.935 %)\n",
            "Epoch: 96   loss: 1.50939  accuracy: 12180 / 12800 (95.156 %)\n",
            "Epoch: 96   loss: 1.51180  accuracy: 12152 / 12800 (94.938 %)\n",
            "Epoch: 96   loss: 1.50953  accuracy: 12183 / 12800 (95.180 %)\n",
            "Epoch: 96 Completed !!!! accuracy: 10990 / 11648 (94.919 %)\n",
            "Epoch: 97   loss: 1.51113  accuracy: 12158 / 12800 (94.984 %)\n",
            "Epoch: 97   loss: 1.51442  accuracy: 12118 / 12800 (94.672 %)\n",
            "Epoch: 97   loss: 1.50852  accuracy: 12193 / 12800 (95.258 %)\n",
            "Epoch: 97 Completed !!!! accuracy: 11047 / 11648 (94.941 %)\n",
            "Epoch: 98   loss: 1.51193  accuracy: 12149 / 12800 (94.914 %)\n",
            "Epoch: 98   loss: 1.51035  accuracy: 12171 / 12800 (95.086 %)\n",
            "Epoch: 98   loss: 1.50997  accuracy: 12176 / 12800 (95.125 %)\n",
            "Epoch: 98 Completed !!!! accuracy: 11020 / 11648 (94.941 %)\n",
            "Epoch: 99   loss: 1.51024  accuracy: 12171 / 12800 (95.086 %)\n",
            "Epoch: 99   loss: 1.51069  accuracy: 12167 / 12800 (95.055 %)\n",
            "Epoch: 99   loss: 1.51064  accuracy: 12165 / 12800 (95.039 %)\n",
            "Epoch: 99 Completed !!!! accuracy: 11014 / 11648 (94.943 %)\n",
            "Epoch: 100   loss: 1.51006  accuracy: 12176 / 12800 (95.125 %)\n",
            "Epoch: 100   loss: 1.51245  accuracy: 12145 / 12800 (94.883 %)\n",
            "Epoch: 100   loss: 1.50785  accuracy: 12205 / 12800 (95.352 %)\n",
            "Epoch: 100 Completed !!!! accuracy: 10994 / 11648 (94.949 %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXx7vWj0cnRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), '/content/resnet101')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWhtoZkyEKCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "9ebcf210-c490-49b1-db54-c81eebc620b9"
      },
      "source": [
        "losses"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor(0.2445, device='cuda:0'),\n",
              " tensor(0.3343, device='cuda:0'),\n",
              " tensor(0.3752, device='cuda:0'),\n",
              " tensor(0.4100, device='cuda:0')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ6FV80IX3z7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "86d15cca-c5cd-41dd-b615-7b9c725f659d"
      },
      "source": [
        "model.eval()\n",
        "running_loss = 0.0\n",
        "correct, total = 0, 0\n",
        "#correct_epoch, total_epoch = 0, 0\n",
        "for i, data in enumerate(testloader):\n",
        "    inp,lab = data[0].to(device),data[1].to(device)\n",
        "    out = model(inp) \n",
        "    c = (torch.argmax(out,1)==lab)\n",
        "    correct+=torch.sum(c)\n",
        "    total += batch_size\n",
        "    \n",
        "print('accuracy: ',100*correct/total,'')    "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:  tensor(80, device='cuda:0') \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
